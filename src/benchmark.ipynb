{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2687881a",
   "metadata": {},
   "source": [
    "## Датасет для бенчмаркинга моделей суммаризации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867fd7f1",
   "metadata": {},
   "source": [
    "Реферирование - создание краткого содержания по тексту. \n",
    "\n",
    "Метрики качества моделей реферирования (ROUGE, BLEU и др.) основаны на сопоставлении реферата, полученного моделью, с эталонным рефератом (то есть таким, который написал человек после прочтения исходного текста). \n",
    "\n",
    "Собирать датасет пар <текст, эталонный реферат> дорого!\n",
    "\n",
    "Решение: краткие содержания c briefly.ru.\n",
    "\n",
    "Собираем датасет пар <текст книги, краткое содержание>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171d8cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "\n",
    "from rouge import Rouge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753e6c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "tokenizer = Tokenizer('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "244447cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "luhn = LuhnSummarizer()\n",
    "text_rank = TextRankSummarizer()\n",
    "lex_rank = LexRankSummarizer()\n",
    "lsa = LsaSummarizer()\n",
    "\n",
    "summarizers = [luhn, text_rank, lex_rank, lsa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe32877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, summarizer, summary_len):\n",
    "#     print(summarizer.__class__, '...')\n",
    "    parser = PlaintextParser.from_string(text, tokenizer)\n",
    "    predicted_summary = summarizer(parser.document, summary_len)\n",
    "    predicted_summary = ' '.join([str(s) for s in predicted_summary])\n",
    "    return predicted_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85298d47",
   "metadata": {},
   "source": [
    "В данном ноутбуке проведем бенчмаркинг моделей реферирования без учителя с помощью нашего датасета.\n",
    "\n",
    "Будем использовать метрики качества реферирования Rouge.\n",
    "\n",
    "Сравним результаты с Gazeta dataset (https://arxiv.org/abs/2006.11063)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec82407a",
   "metadata": {},
   "source": [
    "### Датасет gazeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a7bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gazeta_df = pd.read_json('gazeta/test.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8989eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5770"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gazeta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97a7f663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# сгенерим саммари для датасета gazeta и вычислим для них ROUGE-метрики \n",
    "\n",
    "gazeta_results = [None] * len(gazeta_df)\n",
    "\n",
    "for i in range(len(gazeta_df)): \n",
    "    text = gazeta_df.loc[i].text\n",
    "    reference = gazeta_df.loc[i].summary\n",
    "    ref_doc = PlaintextParser.from_string(reference, tokenizer).document\n",
    "    summary_len = len(ref_doc.sentences) \n",
    "    \n",
    "    result_for_text = []\n",
    "    for summarizer in summarizers:\n",
    "        hypothesis = summarize(text, summarizer, summary_len)\n",
    "        scores = rouge.get_scores(hypothesis, reference)\n",
    "        result_for_text.append([scores[0]['rouge-1']['f'], scores[0]['rouge-2']['f'], scores[0]['rouge-l']['f']])\n",
    "    \n",
    "    gazeta_results[i] = result_for_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e973d44a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gazeta_results = np.array(gazeta_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6585a8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17066938, 0.04617214, 0.15357187],\n",
       "       [0.15079518, 0.03627782, 0.1353037 ],\n",
       "       [0.17230475, 0.04771969, 0.15645291],\n",
       "       [0.14398278, 0.03200836, 0.12893452]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gazeta_results.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b993947",
   "metadata": {},
   "source": [
    "### Наш датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14a78b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_path = 'lib/library/books/'\n",
    "summaries_path = 'lib/library/summaries/'\n",
    "generated_path = 'generated/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32dbc612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерим саммари разными методами и сохраним в файлы (поскольку тексты все-таки большие)\n",
    "\n",
    "filenames = os.listdir(books_path)\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    with open(books_path + filenames[i], 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    with open(summaries_path + filenames[i], 'r', encoding='utf-8') as f:\n",
    "        reference = f.read()\n",
    "    ref_doc = PlaintextParser.from_string(reference, tokenizer).document\n",
    "    summary_len = len(ref_doc.sentences)\n",
    "#     print(i+1)\n",
    "#     print(len(PlaintextParser.from_string(text, tokenizer).document.sentences), ' -> ', summary_len) \n",
    "    \n",
    "    result_for_text = []\n",
    "    for n, summarizer in enumerate(summarizers):\n",
    "        hypothesis = summarize(text, summarizer, summary_len)\n",
    "        with open(generated_path + str(n) + '/' + filenames[i], 'w') as f:\n",
    "            f.write(hypothesis)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d23236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# теперь получим ROUGE-метрики для сгенерированных саммари \n",
    "\n",
    "our_results = []\n",
    "filenames = os.listdir(generated_path+'0/')\n",
    "for filename in filenames:\n",
    "    result_for_text = []\n",
    "    with open(summaries_path + filename, 'r', encoding='utf-8') as f:\n",
    "        reference = f.read()\n",
    "    for i in range(4):\n",
    "        with open(generated_path+str(i)+'/'+filename, 'r') as f:\n",
    "            hypothesis = f.read()\n",
    "            scores = rouge.get_scores(hypothesis, reference)\n",
    "            result_for_text.append([scores[0]['rouge-1']['f'], scores[0]['rouge-2']['f'], scores[0]['rouge-l']['f']])\n",
    "    our_results.append(result_for_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81ef479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_results = np.array(our_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5190f1d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15132326, 0.03291042, 0.14136158],\n",
       "       [0.14364756, 0.03324122, 0.13419271],\n",
       "       [0.13101212, 0.01841673, 0.12589934],\n",
       "       [0.15114855, 0.0274097 , 0.14282233]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_results.mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
